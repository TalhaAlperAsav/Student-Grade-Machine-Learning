# Loading the installed libraries
library(ISLR)
library(ggplot2)
library(lattice)
library(caret)
library(dplyr)
library(e1071)
library(class)
library(tidyverse)
library(reshape2)
# Reading the .csv for Portuguese lecture
studentPorData = read.table("C:/Users/ALPER ASAV/Desktop/Veri Madenciliği/student+performance/student/student-por.csv",sep=";",header=TRUE)
column_names <- names(studentPorData)
# Label Encoding for binary categorical variables
studentPorData$sex <- as.numeric(factor(studentPorData$sex))
studentPorData$address <- as.numeric(factor(studentPorData$address))
studentPorData$famsize <- as.numeric(factor(studentPorData$famsize))
studentPorData$Pstatus <- as.numeric(factor(studentPorData$Pstatus))
studentPorData$schoolsup <- as.numeric(factor(studentPorData$schoolsup))
studentPorData$famsup <- as.numeric(factor(studentPorData$famsup))
studentPorData$paid <- as.numeric(factor(studentPorData$paid))
studentPorData$activities <- as.numeric(factor(studentPorData$activities))
studentPorData$nursery <- as.numeric(factor(studentPorData$nursery))
studentPorData$higher <- as.numeric(factor(studentPorData$higher))
studentPorData$internet <- as.numeric(factor(studentPorData$internet))
studentPorData$romantic <- as.numeric(factor(studentPorData$romantic))
# One-Hot Encoding using the 'model.matrix' function
encodedData <- model.matrix(~ school + Mjob + Fjob + reason + guardian, data = studentPorData)
studentPorData <- cbind(studentPorData[, -which(names(studentPorData) %in% c("school", "Mjob", "Fjob", "reason", "guardian"))], encodedData)
# Convert numeric variables to numeric format
studentPorData$age <- as.numeric(studentPorData$age)
studentPorData$Medu <- as.numeric(studentPorData$Medu)
studentPorData$Fedu <- as.numeric(studentPorData$Fedu)
studentPorData$traveltime <- as.numeric(studentPorData$traveltime)
studentPorData$studytime <- as.numeric(studentPorData$studytime)
studentPorData$failures <- as.numeric(studentPorData$failures)
studentPorData$famrel <- as.numeric(studentPorData$famrel)
studentPorData$freetime <- as.numeric(studentPorData$freetime)
studentPorData$goout <- as.numeric(studentPorData$goout)
studentPorData$Dalc <- as.numeric(studentPorData$Dalc)
studentPorData$Walc <- as.numeric(studentPorData$Walc)
studentPorData$health <- as.numeric(studentPorData$health)
studentPorData$absences <- as.numeric(studentPorData$absences)
studentPorData$G1 <- as.numeric(studentPorData$G1)
studentPorData$G2 <- as.numeric(studentPorData$G2)
studentPorData$G3 <- as.numeric(studentPorData$G3)
# Select relevant features and the target variable
selectedFeatures <- c("sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "traveltime", "studytime", "failures", "schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet", "romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G1", "G2")
subsetPorData <- studentPorData[, c(selectedFeatures, "G3")]
# Build Linear Regression model
linearModel <- train(G3 ~ ., data = trainData, method = "lm")
# Set the seed for reproducibility
set.seed(123)
# Split the data into training and test sets as 0.7 and 0.3
trainIndex <- createDataPartition(subsetPorData$G3, p = 0.7, list = FALSE)
trainData <- subsetPorData[trainIndex, ]
testData <- subsetPorData[-trainIndex, ]
# Building the models so we can predict G3 values
# Build Linear Regression model
linearModel <- train(G3 ~ ., data = trainData, method = "lm")
# Print model summary
print(linearModel)
# Build Random Forest model
rfModel <- train(G3 ~ ., data = trainData, method = "rf")
# Build Random Forest model
rfModel <- train(G3 ~ ., data = trainData, method = "rf")
# Print model summary
print(rfModel)
library(randomForest)
install.packages("gbm")
library(gbm)
# Build Gradient Boosting model
gbmModel <- train(G3 ~ ., data = trainData, method = "gbm", verbose = FALSE)
# Print model summary
print(gbmModel)
View(gbmModel)
View(linearModel)
# Build KNN model
knnModel <- train(G3 ~ ., data = trainData, method = "knn")
# Print model summary
print(knnModel)
# Building AdaBoost model
adaboostModel <- train(G3 ~ ., data = trainData, method = "ada")
install.packages("ada")
install.packages("ada")
library(ada)
# Building AdaBoost model
adaboostModel <- train(G3 ~ ., data = trainData, method = "ada")
View(gbmModel)
# Building AdaBoost model
adaboostModel <- train(G3 ~ ., data = trainData, method = "ada")
# Loading the installed libraries
library(ISLR)
library(ggplot2)
library(lattice)
library(caret)
library(dplyr)
library(e1071)
library(class)
library(tidyverse)
library(reshape2)
library(randomForest)
library(gbm)
library(ada)
# Reading the .csv for Portuguese lecture
studentPorData = read.table("C:/Users/ALPER ASAV/Desktop/Veri Madenciliği/student+performance/student/student-por.csv",sep=";",header=TRUE)
column_names <- names(studentPorData)
# Label Encoding for binary categorical variables
studentPorData$sex <- as.numeric(factor(studentPorData$sex))
studentPorData$address <- as.numeric(factor(studentPorData$address))
studentPorData$famsize <- as.numeric(factor(studentPorData$famsize))
studentPorData$Pstatus <- as.numeric(factor(studentPorData$Pstatus))
studentPorData$schoolsup <- as.numeric(factor(studentPorData$schoolsup))
studentPorData$famsup <- as.numeric(factor(studentPorData$famsup))
studentPorData$paid <- as.numeric(factor(studentPorData$paid))
studentPorData$activities <- as.numeric(factor(studentPorData$activities))
studentPorData$nursery <- as.numeric(factor(studentPorData$nursery))
studentPorData$higher <- as.numeric(factor(studentPorData$higher))
studentPorData$internet <- as.numeric(factor(studentPorData$internet))
studentPorData$romantic <- as.numeric(factor(studentPorData$romantic))
# One-Hot Encoding using the 'model.matrix' function
encodedData <- model.matrix(~ school + Mjob + Fjob + reason + guardian, data = studentPorData)
studentPorData <- cbind(studentPorData[, -which(names(studentPorData) %in% c("school", "Mjob", "Fjob", "reason", "guardian"))], encodedData)
# Convert numeric variables to numeric format
studentPorData$age <- as.numeric(studentPorData$age)
studentPorData$Medu <- as.numeric(studentPorData$Medu)
studentPorData$Fedu <- as.numeric(studentPorData$Fedu)
studentPorData$traveltime <- as.numeric(studentPorData$traveltime)
studentPorData$studytime <- as.numeric(studentPorData$studytime)
studentPorData$failures <- as.numeric(studentPorData$failures)
studentPorData$famrel <- as.numeric(studentPorData$famrel)
studentPorData$freetime <- as.numeric(studentPorData$freetime)
studentPorData$goout <- as.numeric(studentPorData$goout)
studentPorData$Dalc <- as.numeric(studentPorData$Dalc)
studentPorData$Walc <- as.numeric(studentPorData$Walc)
studentPorData$health <- as.numeric(studentPorData$health)
studentPorData$absences <- as.numeric(studentPorData$absences)
studentPorData$G1 <- as.numeric(studentPorData$G1)
studentPorData$G2 <- as.numeric(studentPorData$G2)
studentPorData$G3 <- as.numeric(studentPorData$G3)
# Select relevant features and the target variable
selectedFeatures <- c("sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "traveltime", "studytime", "failures", "schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet", "romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G1", "G2")
subsetPorData <- studentPorData[, c(selectedFeatures, "G3")]
# Set the seed for reproducibility
set.seed(123)
# Splitting the data into training and test sets as 0.7 and 0.3
trainIndex <- createDataPartition(subsetPorData$G3, p = 0.7, list = FALSE)
trainData <- subsetPorData[trainIndex, ]
testData <- subsetPorData[-trainIndex, ]
# Building Linear Regression model
linearModel <- train(G3 ~ ., data = trainData, method = "lm")
# Print model summary
print(linearModel)
# Building Random Forest model
rfModel <- train(G3 ~ ., data = trainData, method = "rf")
# Print model summary
print(rfModel)
# Building Gradient Boosting model
gbmModel <- train(G3 ~ ., data = trainData, method = "gbm", verbose = FALSE)
# Print model summary
print(gbmModel)
# Building KNN model
knnModel <- train(G3 ~ ., data = trainData, method = "knn")
# Print model summary
print(knnModel)
# Building AdaBoost model
adaboostModel <- train(G3 ~ ., data = trainData, method = "ada")
# Building AdaBoost model for regression
adaboostModel <- train(G3 ~ ., data = trainData, method = "adaboost")
install.packages("fastAdaboost")
library(fastAdaboost)
# Building AdaBoost model for regression
adaboostModel <- train(G3 ~ ., data = trainData, method = "adaboost")
# Building AdaBoost model for regression
adaboostModel <- train(G3 ~ ., data = trainData, method = "adaboost")
library(caret)
# Building AdaBoost model for regression
adaboostModel <- train(G3 ~ ., data = trainData, method = "adaboost")
# Building Decision Tree model
treeModel <- train(G3 ~ ., data = trainData, method = "rpart")
# Print model summary
print(treeModel)
# Feature Scaling
preProcValues <- preProcess(trainData[, -which(names(trainData) == "G3")], method = c("center", "scale"))
trainDataScaled <- predict(preProcValues, trainData)
testDataScaled <- predict(preProcValues, testData)
# Model Evaluation Function
evaluateModel <- function(model, testData) {
predictions <- predict(model, testData)
rmse <- sqrt(mean((testData$G3 - predictions)^2))
return(rmse)
# Evaluate Models
linearModelRMSE <- evaluateModel(linearModel, testDataScaled)
rfModelRMSE <- evaluateModel(rfModel, testDataScaled)
gbmModelRMSE <- evaluateModel(gbmModel, testDataScaled)
knnModelRMSE <- evaluateModel(knnModel, testDataScaled)
adaboostModelRMSE <- evaluateModel(adaboostModel, testDataScaled)
treeModelRMSE <- evaluateModel(treeModel, testDataScaled)
# Print RMSEs
print(paste("Linear Model RMSE:", linearModelRMSE))
print(paste("Random Forest Model RMSE:", rfModelRMSE))
print(paste("Gradient Boosting Model RMSE:", gbmModelRMSE))
print(paste("KNN Model RMSE:", knnModelRMSE))
print(paste("AdaBoost Model RMSE:", adaboostModelRMSE))
print(paste("Decision Tree Model RMSE:", treeModelRMSE))
print(paste("Linear Model RMSE:", linearModelRMSE))
print(paste("Random Forest Model RMSE:", rfModelRMSE))
print(paste("Gradient Boosting Model RMSE:", gbmModelRMSE))
print(paste("KNN Model RMSE:", knnModelRMSE))
print(paste("AdaBoost Model RMSE:", adaboostModelRMSE))
print(paste("Decision Tree Model RMSE:", treeModelRMSE))
View(treeModel)
